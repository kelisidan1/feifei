<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"luke-blog.netlify.app","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="我爱学习！~~~">
<meta property="og:type" content="website">
<meta property="og:title" content="Luke-blog">
<meta property="og:url" content="https://luke-blog.netlify.app/index.html">
<meta property="og:site_name" content="Luke-blog">
<meta property="og:description" content="我爱学习！~~~">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Luke">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://luke-blog.netlify.app/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>Luke-blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Luke-blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Legends never die！</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://luke-blog.netlify.app/2023/04/28/Building%20configuration/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/headIcon.jpg">
      <meta itemprop="name" content="Luke">
      <meta itemprop="description" content="我爱学习！~~~">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Luke-blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/04/28/Building%20configuration/" class="post-title-link" itemprop="url">未命名</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-04-28 09:39:39" itemprop="dateCreated datePublished" datetime="2023-04-28T09:39:39+08:00">2023-04-28</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line">Building configuration...</span><br><span class="line"></span><br><span class="line">Current configuration : 1094 bytes</span><br><span class="line">!</span><br><span class="line">version 15.1</span><br><span class="line">no service timestamps log datetime msec</span><br><span class="line">no service timestamps debug datetime msec</span><br><span class="line">no service password-encryption</span><br><span class="line">!</span><br><span class="line">hostname Out-Router</span><br><span class="line">!</span><br><span class="line">!</span><br><span class="line">!</span><br><span class="line">!</span><br><span class="line">!</span><br><span class="line">!</span><br><span class="line">!</span><br><span class="line">!</span><br><span class="line">no ip cef</span><br><span class="line">no ipv6 cef</span><br><span class="line">!</span><br><span class="line">!</span><br><span class="line">!</span><br><span class="line">!</span><br><span class="line">license udi pid CISCO2811/K9 sn FTX10176ABZ-</span><br><span class="line">!</span><br><span class="line">!</span><br><span class="line">!</span><br><span class="line">!</span><br><span class="line">!</span><br><span class="line">!</span><br><span class="line">!</span><br><span class="line">!</span><br><span class="line">!</span><br><span class="line">!</span><br><span class="line">!</span><br><span class="line">spanning-tree mode pvst</span><br><span class="line">!</span><br><span class="line">!</span><br><span class="line">!</span><br><span class="line">!</span><br><span class="line">!</span><br><span class="line">!</span><br><span class="line">interface FastEthernet0/0</span><br><span class="line"> ip address 192.168.4.1 255.255.255.0</span><br><span class="line"> ip nat inside</span><br><span class="line"> duplex auto</span><br><span class="line"> speed auto</span><br><span class="line">!</span><br><span class="line">interface FastEthernet0/1</span><br><span class="line"> no ip address</span><br><span class="line"> duplex auto</span><br><span class="line"> speed auto</span><br><span class="line"> shutdown</span><br><span class="line">!</span><br><span class="line">interface Serial0/2/0</span><br><span class="line"> ip address 200.10.10.1 255.255.255.252</span><br><span class="line"> ip nat outside</span><br><span class="line"> clock rate 64000</span><br><span class="line">!</span><br><span class="line">interface Serial0/2/1</span><br><span class="line"> no ip address</span><br><span class="line"> clock rate 2000000</span><br><span class="line"> shutdown</span><br><span class="line">!</span><br><span class="line">interface Vlan1</span><br><span class="line"> no ip address</span><br><span class="line"> shutdown</span><br><span class="line">!</span><br><span class="line">router ospf 40</span><br><span class="line"> log-adjacency-changes</span><br><span class="line"> network 192.168.4.0 0.0.0.255 area 0</span><br><span class="line"> default-information originate</span><br><span class="line">!</span><br><span class="line">ip nat pool ipPool 200.10.10.1 200.10.10.1 netmask 255.255.255.252</span><br><span class="line">ip nat inside source list 1 pool ipPool overload</span><br><span class="line">ip classless</span><br><span class="line">ip route 0.0.0.0 0.0.0.0 200.10.10.2 </span><br><span class="line">!</span><br><span class="line">ip flow-export version 9</span><br><span class="line">!</span><br><span class="line">!</span><br><span class="line">access-list 1 permit any</span><br><span class="line">!</span><br><span class="line">!</span><br><span class="line">!</span><br><span class="line">!</span><br><span class="line">!</span><br><span class="line">!</span><br><span class="line">line con 0</span><br><span class="line">!</span><br><span class="line">line aux 0</span><br><span class="line">!</span><br><span class="line">line vty 0 4</span><br><span class="line"> login</span><br><span class="line">!</span><br><span class="line">!</span><br><span class="line">!</span><br><span class="line">end</span><br><span class="line"></span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://luke-blog.netlify.app/2023/04/25/PT%E9%85%8D%E7%BD%AE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/headIcon.jpg">
      <meta itemprop="name" content="Luke">
      <meta itemprop="description" content="我爱学习！~~~">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Luke-blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/04/25/PT%E9%85%8D%E7%BD%AE/" class="post-title-link" itemprop="url">PT配置</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-04-25 15:05:31" itemprop="dateCreated datePublished" datetime="2023-04-25T15:05:31+08:00">2023-04-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-04-27 09:47:29" itemprop="dateModified" datetime="2023-04-27T09:47:29+08:00">2023-04-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/" itemprop="url" rel="index"><span itemprop="name">工具使用</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="0x-0-说明"><a href="#0x-0-说明" class="headerlink" title="0x 0 说明"></a>0x 0 说明</h2><p>解决问题：如何快速搭建起一个企业级网络。</p>
<p>注意： 以下的命令均为举例说明</p>
<p># todo ACL控制</p>
<h2 id="0x-1-各类设备命令"><a href="#0x-1-各类设备命令" class="headerlink" title="0x 1 各类设备命令"></a>0x 1 各类设备命令</h2><h3 id="三层交换机（左）"><a href="#三层交换机（左）" class="headerlink" title="三层交换机（左）"></a>三层交换机（左）</h3><blockquote>
<p>  配置Vlan, vtp(vlan数据库)</p>
</blockquote>
<ul>
<li>vtp：它是思科私有协议。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">en</span><br><span class="line">conf t</span><br><span class="line">vtp domain cisco</span><br><span class="line">vtp mode server</span><br><span class="line">vtp password 123456</span><br><span class="line">vlan 10</span><br><span class="line">vlan 20</span><br><span class="line">vlan 30</span><br><span class="line">vlan 40</span><br><span class="line">vlan 50</span><br><span class="line">vlan 60</span><br><span class="line">vlan 70</span><br></pre></td></tr></table></figure>



<blockquote>
<p>  配置ip地址（和防火墙链接的那个口）</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">int g0/0/1 # 进入接口</span><br><span class="line">no switchport # 转成三层接口 (带ip)</span><br><span class="line">ip address 192.168.2.2 255.255.255.0</span><br><span class="line">no shutdown</span><br><span class="line">exit</span><br></pre></td></tr></table></figure>



<blockquote>
<p>  开启路由功能,让其变成有路由功能的交换机</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ip routing</span><br></pre></td></tr></table></figure>



<blockquote>
<p>  链路聚合组</p>
</blockquote>
<p>先创建一个链路聚合组，然后将几个端口放入到这个组当中</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">interface Port-channel 1</span><br><span class="line"> switchport trunk encapsulation dot1q</span><br><span class="line"> switchport mode trunk</span><br><span class="line"></span><br><span class="line">interface GigabitEthernet1/0/22</span><br><span class="line"> switchport trunk encapsulation dot1q</span><br><span class="line"> switchport mode trunk</span><br><span class="line"> channel-group 1 mode on</span><br><span class="line"></span><br><span class="line">interface GigabitEthernet1/0/23</span><br><span class="line"> switchport trunk encapsulation dot1q</span><br><span class="line"> switchport mode trunk</span><br><span class="line"> channel-group 1 mode on</span><br><span class="line"></span><br><span class="line">interface GigabitEthernet1/0/24</span><br><span class="line"> switchport trunk encapsulation dot1q</span><br><span class="line"> switchport mode trunk</span><br><span class="line"> channel-group 1 mode on</span><br></pre></td></tr></table></figure>

<ul>
<li>dot1q就是 IEEE 802.1Q协议，是vlan的一种封装方式，是公有协议</li>
</ul>
<blockquote>
<p>  生成树协议、冗余、优先级</p>
</blockquote>
<ul>
<li>生成树</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">spanning-tree vlan 10,20,30 root primary</span><br><span class="line">spanning-tree mode pvst</span><br><span class="line">spanning-tree vlan 40,50,60,70 root secondary</span><br></pre></td></tr></table></figure>

<ul>
<li>服务器集群的vlan10配置</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">int vlan 10</span><br><span class="line">ip address 192.168.10.254 255.255.255.0</span><br><span class="line">standby 10 ip 192.168.10.252 # 将两个三层交换机看成一个设备</span><br><span class="line">standby 10 priority 120 #当前vlan的优先级是120，如果是vlan10发送过来的数据包</span><br><span class="line">standby 10 preempt #抢占模式，按说vlan10的数据包都是我来接受，但是如果交换机坏了，就要给另一个三层设备进行处理，当我修好之后，就又要抢占回来</span><br><span class="line">standby 10 track GigabitEthernet1/0/7 #上行链路接口，当这个交换机不好使的时候，该把数据包传给谁</span><br></pre></td></tr></table></figure>

<ul>
<li>各个办公机构的vlan配置</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">interface Vlan20</span><br><span class="line"> ip address 192.168.20.254 255.255.255.0</span><br><span class="line"> ip helper-address 192.168.10.1 # IP地址获取的中继（DHCP的地址）</span><br><span class="line"> standby 20 ip 192.168.20.252</span><br><span class="line"> standby 20 priority 120</span><br><span class="line"> standby 20 preempt</span><br><span class="line"> standby 20 track GigabitEthernet1/0/7</span><br><span class="line"></span><br><span class="line">interface Vlan30</span><br><span class="line"> ip address 192.168.30.254 255.255.255.0</span><br><span class="line"> ip helper-address 192.168.10.1</span><br><span class="line"> standby 30 ip 192.168.30.252</span><br><span class="line"> standby 30 priority 120</span><br><span class="line"> standby 30 preempt</span><br><span class="line"> standby 30 track GigabitEthernet1/0/7</span><br><span class="line"> </span><br><span class="line">interface Vlan40</span><br><span class="line"> ip address 192.168.40.254 255.255.255.0</span><br><span class="line"> ip helper-address 192.168.10.1</span><br><span class="line"> standby 40 ip 192.168.40.252</span><br><span class="line"> standby 40 track GigabitEthernet1/0/7</span><br><span class="line"> </span><br><span class="line">interface Vlan50</span><br><span class="line"> ip address 192.168.50.254 255.255.255.0</span><br><span class="line"> ip helper-address 192.168.10.1</span><br><span class="line"> standby 50 ip 192.168.50.252</span><br><span class="line"> standby 50 track GigabitEthernet1/0/7</span><br><span class="line"></span><br><span class="line">interface Vlan60</span><br><span class="line"> ip address 192.168.60.254 255.255.255.0</span><br><span class="line"> ip helper-address 192.168.10.1</span><br><span class="line"> standby 60 ip 192.168.60.252</span><br><span class="line"> standby 60 track GigabitEthernet1/0/7</span><br></pre></td></tr></table></figure>



<h3 id="三层交换机（右）"><a href="#三层交换机（右）" class="headerlink" title="三层交换机（右）"></a>三层交换机（右）</h3><blockquote>
<p>  配置Vlan, vtp(vlan数据库)</p>
</blockquote>
<ul>
<li>vtp：它是思科私有协议。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">en</span><br><span class="line">conf t</span><br><span class="line">vtp domain cisco</span><br><span class="line">vtp mode server</span><br><span class="line">vtp password 123456</span><br><span class="line">vlan 10</span><br><span class="line">vlan 20</span><br><span class="line">vlan 30</span><br><span class="line">vlan 40</span><br><span class="line">vlan 50</span><br><span class="line">vlan 60</span><br><span class="line">vlan 70</span><br></pre></td></tr></table></figure>

<blockquote>
<p>  配置ip地址（和防火墙链接的那个口）</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">int g0/0/1 # 进入接口</span><br><span class="line">no switchport # 转成三层接口 (带ip)</span><br><span class="line">ip address 192.168.2.2 255.255.255.0</span><br><span class="line">no shutdown</span><br><span class="line">exit</span><br></pre></td></tr></table></figure>

<blockquote>
<p>  链路聚合组</p>
</blockquote>
<p>先创建一个链路聚合组，然后将几个端口放入到这个组当中</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">interface Port-channel 1</span><br><span class="line"> switchport trunk encapsulation dot1q</span><br><span class="line"> switchport mode trunk</span><br><span class="line"></span><br><span class="line">interface GigabitEthernet1/0/22</span><br><span class="line"> switchport trunk encapsulation dot1q</span><br><span class="line"> switchport mode trunk</span><br><span class="line"> channel-group 1 mode on</span><br><span class="line"></span><br><span class="line">interface GigabitEthernet1/0/23</span><br><span class="line"> switchport trunk encapsulation dot1q</span><br><span class="line"> switchport mode trunk</span><br><span class="line"> channel-group 1 mode on</span><br><span class="line"></span><br><span class="line">interface GigabitEthernet1/0/24</span><br><span class="line"> switchport trunk encapsulation dot1q</span><br><span class="line"> switchport mode trunk</span><br><span class="line"> channel-group 1 mode on</span><br></pre></td></tr></table></figure>

<ul>
<li>dot1q就是 IEEE 802.1Q协议，是vlan的一种封装方式，是公有协议</li>
</ul>
<blockquote>
<p>  开启路由功能,让其变成有路由功能的交换机</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ip routing</span><br></pre></td></tr></table></figure>



<blockquote>
<p>  vlan和优先级配置</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">interface Vlan10</span><br><span class="line"> ip address 192.168.10.253 255.255.255.0</span><br><span class="line"> standby 10 ip 192.168.10.252</span><br><span class="line"> standby 10 track GigabitEthernet1/0/1</span><br><span class="line"> standby 10 track GigabitEthernet1/0/7</span><br><span class="line"></span><br><span class="line">interface Vlan20</span><br><span class="line"> ip address 192.168.20.253 255.255.255.0</span><br><span class="line"> ip helper-address 192.168.10.1</span><br><span class="line"> standby 20 ip 192.168.20.252</span><br><span class="line"> standby 20 track GigabitEthernet1/0/7</span><br><span class="line"></span><br><span class="line">interface Vlan30</span><br><span class="line"> ip address 192.168.30.253 255.255.255.0</span><br><span class="line"> ip helper-address 192.168.10.1</span><br><span class="line"> standby 30 ip 192.168.30.252</span><br><span class="line"> standby 30 track GigabitEthernet1/0/7</span><br><span class="line"></span><br><span class="line">interface Vlan40</span><br><span class="line"> ip address 192.168.40.253 255.255.255.0</span><br><span class="line"> ip helper-address 192.168.10.1</span><br><span class="line"> standby 40 ip 192.168.40.252</span><br><span class="line"> standby 40 track GigabitEthernet1/0/7</span><br><span class="line"></span><br><span class="line">interface Vlan50</span><br><span class="line"> ip address 192.168.50.253 255.255.255.0</span><br><span class="line"> ip helper-address 192.168.10.1</span><br><span class="line"> standby 50 ip 192.168.50.252</span><br><span class="line"> standby 50 priority 120</span><br><span class="line"> standby 50 preempt</span><br><span class="line"> standby 50 track GigabitEthernet1/0/7</span><br><span class="line"></span><br><span class="line">interface Vlan60</span><br><span class="line"> ip address 192.168.60.253 255.255.255.0</span><br><span class="line"> ip helper-address 192.168.10.1</span><br><span class="line"> standby 60 ip 192.168.60.252</span><br><span class="line"> standby 60 priority 120</span><br><span class="line"> standby 60 preempt</span><br><span class="line"> standby 60 track GigabitEthernet1/0/7</span><br><span class="line"></span><br><span class="line">interface Vlan70</span><br><span class="line"> ip address 192.168.70.254 255.255.255.0</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<h3 id="二层交换机配置"><a href="#二层交换机配置" class="headerlink" title="二层交换机配置"></a>二层交换机配置</h3><blockquote>
<p>   vtp配置（所有二层交换机都要配置）</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vtp domain cisco</span><br><span class="line">vtp mode client</span><br><span class="line">vtp password 123456</span><br></pre></td></tr></table></figure>

<p>这样的话，就相当于每个二层交换机管理的vlan都是一个员工，而三层交换机是leader，由leader对员工进行统一管理</p>
<blockquote>
<p>  接口权限配置(其他二层和vlan10的类似，只要改数字就行)</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">interface GigabitEthernet0/1</span><br><span class="line"> switchport mode trunk</span><br><span class="line"></span><br><span class="line">interface GigabitEthernet0/2</span><br><span class="line"> switchport mode trunk</span><br><span class="line"></span><br><span class="line">interface FastEthernet0/1</span><br><span class="line"> switchport access vlan 10</span><br><span class="line"> switchport mode access</span><br><span class="line"></span><br><span class="line">interface FastEthernet0/2</span><br><span class="line"> switchport access vlan 10</span><br><span class="line"> switchport mode access</span><br><span class="line"></span><br><span class="line">interface FastEthernet0/3</span><br><span class="line"> switchport access vlan 10</span><br><span class="line"> switchport mode access</span><br></pre></td></tr></table></figure>





<h3 id="DHCP服务器配置"><a href="#DHCP服务器配置" class="headerlink" title="DHCP服务器配置"></a>DHCP服务器配置</h3><p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230425163823276.png" alt="image-20230425163823276"></p>
<h3 id="无线AP配置"><a href="#无线AP配置" class="headerlink" title="无线AP配置"></a>无线AP配置</h3><p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230425164012989.png" alt="image-20230425164012989"></p>
<h3 id="防火墙配置"><a href="#防火墙配置" class="headerlink" title="防火墙配置"></a>防火墙配置</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">en</span><br><span class="line">conf t</span><br><span class="line">interface GigabitEthernet1/1</span><br><span class="line">nameif trust-1</span><br><span class="line">security-level 100</span><br><span class="line">ip address 192.168.2.1 255.255.255.0</span><br><span class="line">no shutdown</span><br><span class="line"></span><br><span class="line">interface GigabitEthernet1/2</span><br><span class="line">nameif trust-2</span><br><span class="line">security-level 100</span><br><span class="line">ip address 192.168.3.1 255.255.255.0</span><br><span class="line">no shutdown</span><br><span class="line"> </span><br><span class="line">interface GigabitEthernet1/3</span><br><span class="line">nameif untrust</span><br><span class="line">security-level 0</span><br><span class="line">ip address 192.168.4.2 255.255.255.0</span><br><span class="line">no shutdown</span><br></pre></td></tr></table></figure>





<h3 id="路由器配置（out-router）"><a href="#路由器配置（out-router）" class="headerlink" title="路由器配置（out router）"></a>路由器配置（out router）</h3><blockquote>
<p>  配置ip地址</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">interface FastEthernet0/0</span><br><span class="line"> ip address 192.168.4.1 255.255.255.0</span><br><span class="line"> ip nat inside</span><br><span class="line"></span><br><span class="line">interface Serial0/2/0</span><br><span class="line"> ip address 200.10.10.1 255.255.255.252</span><br><span class="line"> ip nat outside</span><br><span class="line"> clock rate 64000</span><br></pre></td></tr></table></figure>








      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://luke-blog.netlify.app/2023/04/23/%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-step01/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/headIcon.jpg">
      <meta itemprop="name" content="Luke">
      <meta itemprop="description" content="我爱学习！~~~">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Luke-blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/04/23/%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-step01/" class="post-title-link" itemprop="url">动手学习深度学习</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-04-23 10:25:19" itemprop="dateCreated datePublished" datetime="2023-04-23T10:25:19+08:00">2023-04-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-05-04 16:24:10" itemprop="dateModified" datetime="2023-05-04T16:24:10+08:00">2023-05-04</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">动手学深度学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="0x-0学习目录"><a href="#0x-0学习目录" class="headerlink" title="0x 0学习目录"></a>0x 0学习目录</h2><ul>
<li>python语法</li>
<li>数据操作</li>
<li>线性代数</li>
<li>线性回归</li>
<li>Softmax回归+损失函数+图片分类</li>
</ul>
<blockquote>
<p>  后续学习可能需要补充的知识</p>
</blockquote>
<ul>
<li>矩阵论</li>
</ul>
<h2 id="0x-1-Python语法"><a href="#0x-1-Python语法" class="headerlink" title="0x 1 Python语法"></a>0x 1 Python语法</h2><h3 id="with关键字"><a href="#with关键字" class="headerlink" title="with关键字"></a>with关键字</h3><ul>
<li><p>Python 中的 <strong>with</strong> 语句用于异常处理，封装了 <strong>try…except…finally</strong> 编码范式，提高了易用性。</p>
</li>
<li><p><strong>with</strong> 语句使代码更清晰、更具可读性， 它简化了文件流等公共资源的管理。</p>
</li>
</ul>
<h3 id="backward-函数的理解"><a href="#backward-函数的理解" class="headerlink" title="backward()函数的理解"></a>backward()函数的理解</h3><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/sinat_28731575/article/details/90342082">(25条消息) pytorch中backward()函数详解_backward函数_Camlin_Z的博客-CSDN博客</a></p>
<h3 id="yield关键字的理解"><a href="#yield关键字的理解" class="headerlink" title="yield关键字的理解"></a>yield关键字的理解</h3><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/mieleizhi0522/article/details/82142856">(25条消息) python中yield的用法详解——最简单，最清晰的解释_python yield_冯爽朗的博客-CSDN博客</a></p>
<h3 id="张量索引"><a href="#张量索引" class="headerlink" title="张量索引"></a>张量索引</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">features = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]</span><br><span class="line">labels = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">batch_indices = torch.tensor([<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>])</span><br><span class="line"></span><br><span class="line">selected_features = features[batch_indices] <span class="comment"># tensor([1, 3, 5])</span></span><br><span class="line">selected_labels = labels[batch_indices] <span class="comment"># tensor([1, 1, 1])</span></span><br></pre></td></tr></table></figure>



<h3 id="的含义"><a href="#的含义" class="headerlink" title="*的含义"></a>*的含义</h3><blockquote>
<p>  Q</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_array</span>(<span class="params">data_arrays,batch_size,is_train=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;构造一个PyTorch的数据迭代器&quot;&quot;&quot;</span></span><br><span class="line">    dataset = data.TensorDataset(*data_arrays)</span><br><span class="line">    <span class="keyword">return</span> data.DataLoader(dataset,batch_size,shuffle=is_train)</span><br></pre></td></tr></table></figure>

<p>其中，*data_arrays是什么意思</p>
<blockquote>
<p>  A</p>
</blockquote>
<p><code>data_arrays</code>是一个由多个张量组成的元组，这些张量包含了数据集中的特征和标签数据。在Python中，<em>被称为可变位置参数，它可以将一个元组或列表展开成独立的位置参数。在这里，</em>data_arrays将元组中的每个张量作为单独的参数传递给了<code>TensorDataset</code>构造函数。</p>
<p>举个例子，如果我们有以下张量：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">features = torch.tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])</span><br><span class="line">labels = torch.tensor([1.0, 2.0, 3.0])</span><br></pre></td></tr></table></figure>

<p>那么调用<code>TensorDataset(*data_arrays)</code>就相当于调用<code>TensorDataset(features, labels)</code>。这样，我们就可以使用PyTorch提供的数据集和数据迭代器来高效地读取和处理大规模数据集。</p>
<p>在<code>load_array</code>函数中，我们首先通过<code>TensorDataset</code>将特征和标签数据组合成一个<code>dataset</code>对象。然后，我们使用<code>DataLoader</code>来创建一个迭代器，每次迭代时可以返回一个大小为<code>batch_size</code>的小批次数据。如果<code>is_train</code>为True，则打乱数据集顺序以增加随机性（即使特征和标签依然是匹配的）。这里的返回结果就是一个PyTorch数据迭代器，可以用于训练和测试深度学习模型。</p>
<blockquote>
<p>  以下的两种写法是一样的</p>
</blockquote>
<ul>
<li>写法1：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">file = <span class="built_in">open</span>(<span class="string">&#x27;./test_runoob.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    file.write(<span class="string">&#x27;hello world&#x27;</span>)</span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line">    file.close()</span><br></pre></td></tr></table></figure>

<ul>
<li>写法2：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./test_runoob.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">    file.write(<span class="string">&#x27;hello world !&#x27;</span>)</span><br></pre></td></tr></table></figure>





<h3 id="torchvision库"><a href="#torchvision库" class="headerlink" title="torchvision库"></a>torchvision库</h3><p>pytorch对计算机视觉实现的库</p>
<p><img src="https://i0.hdslb.com/bfs/note/69c34e7757b5f637c5bd8f053968896aef442e6e.png@!web-comment-note.webp" alt="img"></p>
<h2 id="0x-2数据操作"><a href="#0x-2数据操作" class="headerlink" title="0x 2数据操作"></a>0x 2数据操作</h2><h3 id="N维数组"><a href="#N维数组" class="headerlink" title="N维数组"></a>N维数组</h3><p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230423102655059.png" alt="image-20230423102655059"></p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230423102712809.png" alt="image-20230423102712809"></p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230423102800722.png" alt="image-20230423102800722"></p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230423102820736.png" alt="image-20230423102820736"></p>
<ul>
<li>[1:3,1:]的意思是<ul>
<li>从第1行到第2行</li>
<li>从第1列到最后一列</li>
</ul>
</li>
<li>[::3,::2]的意思是<ul>
<li>从第0行到最后一行，步长为3 行定位</li>
<li>从第0列到最后一列，步长为2列定位</li>
</ul>
</li>
</ul>
<blockquote>
<p>  仓库里面还有jupyter notebook可以看代码的讲解。</p>
</blockquote>
<h2 id="0x-2线性代数-下面只记录-不太清楚-x2F-忘记-x2F-有别名-的概念"><a href="#0x-2线性代数-下面只记录-不太清楚-x2F-忘记-x2F-有别名-的概念" class="headerlink" title="0x 2线性代数-下面只记录   不太清楚&#x2F;忘记&#x2F;有别名   的概念"></a>0x 2线性代数-下面只记录   不太清楚&#x2F;忘记&#x2F;有别名   的概念</h2><h3 id="范数"><a href="#范数" class="headerlink" title="范数"></a>范数</h3><p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E6%A1%A3(10)_20_1682240317289.png" alt="未命名文档(10)_20_1682240317289"></p>
<p>暂且理解下面的不等式   类比勾股定理</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230423170039416.png" alt="image-20230423170039416"></p>
<h3 id="置换矩阵"><a href="#置换矩阵" class="headerlink" title="置换矩阵"></a>置换矩阵</h3><p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230423170723670.png" alt="image-20230423170723670"></p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230423170711424.png" alt="image-20230423170711424"></p>
<h3 id="哈达玛积"><a href="#哈达玛积" class="headerlink" title="哈达玛积"></a>哈达玛积</h3><p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230424090101577.png" alt="image-20230424090101577"></p>
<p>其中，A、B都张这样：</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230424090228191.png" alt="image-20230424090228191"></p>
<h3 id="讲矩阵导数时遇到的一些奇奇怪怪的东西："><a href="#讲矩阵导数时遇到的一些奇奇怪怪的东西：" class="headerlink" title="讲矩阵导数时遇到的一些奇奇怪怪的东西："></a>讲矩阵导数时遇到的一些奇奇怪怪的东西：</h3><ul>
<li>不可导点处，假装它可导</li>
</ul>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230424100902679.png" alt="image-20230424100902679"></p>
<ul>
<li>梯度&#x2F;对向量求导（零基础入门系列当中也有讲过）</li>
</ul>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230424101327209.png" alt="image-20230424101327209"></p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230424101505648.png" alt="image-20230424101505648"></p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230424101552092.png" alt="image-20230424101552092"></p>
<ul>
<li>链导法</li>
</ul>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230424103410413.png" alt="image-20230424103410413"></p>
<ul>
<li>计算图（方便计算机来做求导运算）</li>
</ul>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230424103652967.png" alt="image-20230424103652967"></p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230424103800619.png" alt="image-20230424103800619"></p>
<p>上面的是显式构造，下面的是隐式构造</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230424104120651.png" alt="image-20230424104120651"></p>
<h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><h3 id="盘代码逻辑"><a href="#盘代码逻辑" class="headerlink" title="盘代码逻辑"></a>盘代码逻辑</h3><p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E6%A1%A3(10)_21_1683167816691.png" alt="未命名文档(10)_21_1683167816691"></p>
<h2 id="Softmax回归-损失函数-图片分类"><a href="#Softmax回归-损失函数-图片分类" class="headerlink" title="Softmax回归+损失函数+图片分类"></a>Softmax回归+损失函数+图片分类</h2><h3 id="它能解决什么问题？e-g"><a href="#它能解决什么问题？e-g" class="headerlink" title="它能解决什么问题？e.g."></a>它能解决什么问题？e.g.</h3><p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230503111030180.png" alt="image-20230503111030180"></p>
<h3 id="softmax回归"><a href="#softmax回归" class="headerlink" title="softmax回归"></a>softmax回归</h3><p><img src="https://zh.d2l.ai/_images/softmaxreg.svg"></p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/Screenshot_20230504_155500_com.jideos.jnotes.png" alt="Screenshot_20230504_155500_com.jideos.jnotes"></p>
<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/400E564C26F275CC7763A4B07853619B.jpg" alt="img"></p>
<h3 id=""><a href="#" class="headerlink" title=""></a></h3>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://luke-blog.netlify.app/2023/04/23/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E6%80%9D%E8%B7%AF%E7%AF%87/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/headIcon.jpg">
      <meta itemprop="name" content="Luke">
      <meta itemprop="description" content="我爱学习！~~~">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Luke-blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/04/23/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E6%80%9D%E8%B7%AF%E7%AF%87/" class="post-title-link" itemprop="url">动手学深度学习-思路篇</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2023-04-23 09:21:00 / 修改时间：09:29:10" itemprop="dateCreated datePublished" datetime="2023-04-23T09:21:00+08:00">2023-04-23</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">动手学深度学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="必学章节"><a href="#必学章节" class="headerlink" title="必学章节"></a>必学章节</h2><ol>
<li>预备知识</li>
<li>线性神经网络</li>
<li>多层感知机： 4.1-4.8</li>
<li>深度学习计算</li>
<li>图像必学<ol>
<li>卷积神经网络</li>
<li>现代卷积神经网络：7.1, 7.2, 7.5, 7.6, 7.7</li>
<li>13 计算机视觉</li>
</ol>
</li>
<li>时序必学（“时序必学”部分先不看，看图像和注意力机制）<ol>
<li>循环神经网络</li>
<li>现代循环神经网络9.1, 9.2, 9.3, 9.4, 9.6, 9.7, 9.8</li>
</ol>
</li>
<li>注意力机制</li>
</ol>
<h2 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h2><p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230423092420803.png" alt="image-20230423092420803"></p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230423092652339.png" alt="image-20230423092652339"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://luke-blog.netlify.app/2023/04/16/%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E9%95%BF%E7%9F%AD%E6%97%B6%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9CLSTM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/headIcon.jpg">
      <meta itemprop="name" content="Luke">
      <meta itemprop="description" content="我爱学习！~~~">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Luke-blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/04/16/%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E9%95%BF%E7%9F%AD%E6%97%B6%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9CLSTM/" class="post-title-link" itemprop="url">零基础入门深度学习-长短时记忆网络LSTM</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-04-16 08:00:12" itemprop="dateCreated datePublished" datetime="2023-04-16T08:00:12+08:00">2023-04-16</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-04-22 15:18:02" itemprop="dateModified" datetime="2023-04-22T15:18:02+08:00">2023-04-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">零基础入门深度学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="0x0-前置知识"><a href="#0x0-前置知识" class="headerlink" title="0x0 前置知识"></a>0x0 前置知识</h2><p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E6%A1%A3(10)_11_1681633813176.png" alt="未命名文档(10)_11_1681633813176"></p>
<h2 id="0x1-什么什么，这是什么"><a href="#0x1-什么什么，这是什么" class="headerlink" title="0x1 什么什么，这是什么"></a>0x1 什么什么，这是什么</h2><ul>
<li>Long Short-term Memory (LSTM)   比较长的短时记忆</li>
</ul>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230416083511755.png" alt="image-20230416083511755"></p>
<h2 id="0x2-视频学习🖊"><a href="#0x2-视频学习🖊" class="headerlink" title="0x2 视频学习🖊"></a>0x2 视频学习🖊</h2><h3 id="LSTM解决了什么问题？"><a href="#LSTM解决了什么问题？" class="headerlink" title="LSTM解决了什么问题？"></a>LSTM解决了什么问题？</h3><ul>
<li>解决了梯度消失，但是没有解决梯度爆炸。<ul>
<li>为什么能解决梯度消失的问题？</li>
</ul>
</li>
</ul>
<h3 id="LSTM的Solution"><a href="#LSTM的Solution" class="headerlink" title="LSTM的Solution"></a>LSTM的Solution</h3><p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230416140347307.png" alt="image-20230416140347307"></p>
<p>在t 时刻，LSTM的输入有三个：</p>
<ul>
<li>x<sub>t</sub> </li>
<li>t-1时刻的LSTM输出值h<sub>t-1</sub></li>
<li>t-1时刻的单元状态c<sub>t-1</sub></li>
</ul>
<p>输出有两个</p>
<ul>
<li><p>h<sub>t</sub>：当前时刻LSTM输出值</p>
</li>
<li><p>c<sub>t</sub>：当前时刻的单元状态</p>
</li>
</ul>
<h3 id="But-怎么样让状态长期保存？？？？？"><a href="#But-怎么样让状态长期保存？？？？？" class="headerlink" title="But, 怎么样让状态长期保存？？？？？"></a>But, 怎么样让状态长期保存？？？？？</h3><p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230416141316946.png" alt="image-20230416141316946"></p>
<ul>
<li><p>开关怎么实现？&#x3D;&gt; 门的概念</p>
<ul>
<li>啥是门？ &#x3D;&gt; 一层全连接层，输入是一个向量，输出是一个0到1之间的实数向量</li>
<li>门可以表示成这样：<img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230416142120679.png" alt="image-20230416142120679"></li>
<li>其中<em>σ</em>是sigmoid函数，所以门的状态都是半开半闭，这意味着<ul>
<li>我可以决定c<sub> t − 1 </sub>有多少保留到当前时刻c<sub> t </sub></li>
<li>当前时刻网络的输入x<sub> t </sub> 有多少保存到单元状态c<sub> t </sub></li>
<li>LSTM用输出门（output gate）来控制单元状态c<sub> t </sub>有多少输出到LSTM的当前输出值h <sub> t </sub>。</li>
</ul>
</li>
</ul>
</li>
<li><p>注意看，h<sub>t</sub>的输出其实会copy一份到y<sub>t</sub></p>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E6%A1%A3(10)_9_1681631918050.png" alt="未命名文档(10)_9_1681631918050"></p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E6%A1%A3(10)_10_1681631946512.png" alt="未命名文档(10)_10_1681631946512"></p>
<h3 id="如何对LSTM进行训练"><a href="#如何对LSTM进行训练" class="headerlink" title="如何对LSTM进行训练"></a>如何对LSTM进行训练</h3><p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E6%A1%A3(10)_12_1681717842497.png" alt="未命名文档(10)_12_1681717842497"></p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E6%A1%A3(10)_13_1681717868343.png" alt="未命名文档(10)_13_1681717868343"></p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E6%A1%A3(10)_14_1681717890187.png" alt="未命名文档(10)_14_1681717890187"></p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E6%A1%A3(10)_15_1681717919679.png" alt="未命名文档(10)_15_1681717919679"></p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E6%A1%A3(10)_16_1681717955710.png" alt="未命名文档(10)_16_1681717955710"></p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E6%A1%A3(10)_17_1681717978845.png" alt="未命名文档(10)_17_1681717978845"></p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E6%A1%A3(10)_18_1681718000135.png" alt="未命名文档(10)_18_1681718000135"></p>
<h2 id="0x3-python小知识学习"><a href="#0x3-python小知识学习" class="headerlink" title="0x3 python小知识学习"></a>0x3 python小知识学习</h2><p>np.transpose()函数</p>
<p>一句话简单说：改变np数组结构的函数，类比excel表当中x轴y轴互换操作。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">x = np.arange(<span class="number">4</span>).reshape((<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;-------------------------&#x27;</span>)</span><br><span class="line">x = np.transpose(x)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;====================&#x27;</span>)</span><br><span class="line">y = np.arange(<span class="number">12</span>).reshape((<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>))</span><br><span class="line"><span class="built_in">print</span>(y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;-------------------------&#x27;</span>)</span><br><span class="line">y = np.transpose(y,(<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>))</span><br><span class="line"><span class="built_in">print</span>(y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过transpose()函数改变了x的索引值为（2，1，0），对应（y，x，z）</span></span><br><span class="line"><span class="comment"># 也就是 原本的 y[1][0][0]的元素</span></span><br><span class="line"><span class="comment"># 变成了 现在的 y[0][0][1]元素</span></span><br><span class="line"><span class="comment"># 二维的话就相当于转置</span></span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://luke-blog.netlify.app/2023/04/15/%E6%96%AD%E5%89%91%E9%87%8D%E9%93%B8%E4%B9%8B%E6%97%A5%EF%BC%8C%E9%AA%91%E5%A3%AB%E5%BD%92%E6%9D%A5%E4%B9%8B%E6%97%B6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/headIcon.jpg">
      <meta itemprop="name" content="Luke">
      <meta itemprop="description" content="我爱学习！~~~">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Luke-blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/04/15/%E6%96%AD%E5%89%91%E9%87%8D%E9%93%B8%E4%B9%8B%E6%97%A5%EF%BC%8C%E9%AA%91%E5%A3%AB%E5%BD%92%E6%9D%A5%E4%B9%8B%E6%97%B6/" class="post-title-link" itemprop="url">断剑重铸之日，骑士归来之时</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-04-15 21:08:26" itemprop="dateCreated datePublished" datetime="2023-04-15T21:08:26+08:00">2023-04-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-04-17 08:11:52" itemprop="dateModified" datetime="2023-04-17T08:11:52+08:00">2023-04-17</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">零基础入门深度学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="为什么文章的推导看不懂？"><a href="#为什么文章的推导看不懂？" class="headerlink" title="为什么文章的推导看不懂？"></a>为什么文章的推导看不懂？</h2><ol>
<li>没仔细看</li>
<li>缺乏前置知识</li>
<li>缺少全局的观念</li>
</ol>
<h2 id="整个系列的精华"><a href="#整个系列的精华" class="headerlink" title="整个系列的精华"></a>整个系列的精华</h2><ol>
<li>向量化编程</li>
<li>BP的思路</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://luke-blog.netlify.app/2023/04/13/%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/headIcon.jpg">
      <meta itemprop="name" content="Luke">
      <meta itemprop="description" content="我爱学习！~~~">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Luke-blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/04/13/%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" class="post-title-link" itemprop="url">零基础入门深度学习-循环神经网络</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-04-13 16:59:46" itemprop="dateCreated datePublished" datetime="2023-04-13T16:59:46+08:00">2023-04-13</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-04-17 10:26:18" itemprop="dateModified" datetime="2023-04-17T10:26:18+08:00">2023-04-17</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">零基础入门深度学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="0x-0-一种形象化的理解方式"><a href="#0x-0-一种形象化的理解方式" class="headerlink" title="0x 0 一种形象化的理解方式"></a>0x 0 一种形象化的理解方式</h2><p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230415091324304.png" alt="image-20230415091324304"></p>
<p>一定要看这个：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1z5411f7Bm/?spm_id_from=333.337.search-card.all.click&vd_source=be08cd9cc4a3d6f3fec83590352fca21">【循环神经网络】5分钟搞懂RNN，3D动画深入浅出_哔哩哔哩_bilibili</a></p>
<p>前置知识：矩阵对矩阵的求导、矩阵对向量的求导运算</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E6%A1%A3(10)_8_1681698211614.png" alt="未命名文档(10)_8_1681698211614"></p>
<h2 id="0x-1-RNN能干啥？"><a href="#0x-1-RNN能干啥？" class="headerlink" title="0x 1 RNN能干啥？"></a>0x 1 RNN能干啥？</h2><ul>
<li><p>RNN可以为<strong>语言模型</strong>来建模</p>
</li>
<li><p>比如，当我们在理解一句话意思时，孤立的理解这句话的每个词是不够的，我们需要处理这些词连接起来的整个<strong>序列</strong>；当我们处理视频的时候，我们也不能只单独的去分析每一帧，而要分析这些帧连接起来的整个序列。这时，就需要用到深度学习领域中另一类非常重要神经网络：<strong>循环神经网络</strong>(Recurrent Neural Network)。</p>
</li>
</ul>
<h2 id="0x-2-RNN理论知识学习"><a href="#0x-2-RNN理论知识学习" class="headerlink" title="0x 2 RNN理论知识学习"></a>0x 2 RNN理论知识学习</h2><h3 id="最简单的RNN张什么样"><a href="#最简单的RNN张什么样" class="headerlink" title="最简单的RNN张什么样"></a>最简单的RNN张什么样</h3><p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230415083548108.png" alt="image-20230415083548108"></p>
<p>它会有这样一个式子：</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230415083623060.png" alt="image-20230415083623060"></p>
<p>反复将式2代入式1，就有：</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230415083719695.png" alt="image-20230415083719695"></p>
<p>So，输入的前半部分会影响到后半部分的输出。</p>
<h3 id="上点强度——双向RNN"><a href="#上点强度——双向RNN" class="headerlink" title="上点强度——双向RNN"></a>上点强度——双向RNN</h3><p>有两个W，但是这里用A表示。</p>
<p>A1用于正向计算</p>
<p>A2用于反向计算</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230415085957116.png" alt="image-20230415085957116"></p>
<h3 id="循环神经网络的训练"><a href="#循环神经网络的训练" class="headerlink" title="循环神经网络的训练"></a>循环神经网络的训练</h3><blockquote>
<p>  BPTT算法</p>
</blockquote>
<p>针对循环层的训练算法，原理与BP一致</p>
<p>步骤：</p>
<ol>
<li>前向计算求结果</li>
<li>反向计算求误差</li>
<li>随机下降更权重</li>
</ol>
<h4 id="误差怎么求"><a href="#误差怎么求" class="headerlink" title="误差怎么求"></a>误差怎么求</h4><p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E6%A1%A3(10)_6_1681526047319.png" alt="未命名文档(10)_6_1681526047319"></p>
<h4 id="怎么计算权重的梯度？"><a href="#怎么计算权重的梯度？" class="headerlink" title="怎么计算权重的梯度？"></a>怎么计算权重的梯度？</h4><p>博客当中对矩阵求导，但是我们之前几个博客都是对向量进行求导。</p>
<ul>
<li>对向量求导比一个一个对变量求导快（支持GPU加速且形式更美观）</li>
<li>本质相同，但是形式不同</li>
</ul>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230415140734980.png" alt="image-20230415140734980"></p>
<p>还是两方面考虑</p>
<ul>
<li>T<sub>k</sub>时刻的前层权重更新就和之前的全连接网络更新梯度一样</li>
<li>T<sub>k</sub>时刻计算T<sub>k-s</sub>的梯度是我们要新考虑的东西</li>
</ul>
<p>权重矩阵U和W的计算方法：</p>
<ul>
<li>∇ 是梯度算子，∇ f ( x )就是指f ( x ) 的梯度。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230415111609154.png" alt="image-20230415111609154"></p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230415111655359.png" alt="image-20230415111655359"></p>
<p>最后为什么是加法呢？见下面的推导</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E6%A1%A3(10)_7_1681561677242.png" alt="未命名文档(10)_7_1681561677242"></p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230415111906498.png" alt="image-20230415111906498"></p>
<h3 id="RNN的梯度爆炸和消失问题"><a href="#RNN的梯度爆炸和消失问题" class="headerlink" title="RNN的梯度爆炸和消失问题"></a>RNN的梯度爆炸和消失问题</h3><p>梯度消失 &#x3D;&gt; 训练缓慢 甚至停滞</p>
<p>梯度爆炸 &#x3D;&gt; 可能不收敛</p>
<h2 id="RNN的应用——语言模型"><a href="#RNN的应用——语言模型" class="headerlink" title="RNN的应用——语言模型"></a>RNN的应用——语言模型</h2><p>我当前输入一个词，循环神经网络会帮我预测下一个词要输出什么</p>
<p>Solution: 概率。</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230415154753640.png" alt="image-20230415154753640"></p>
<p>But,这个概率是怎么来的？</p>
<p>Softmax函数</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230415154853403.png" alt="image-20230415154853403"></p>
<p>误差计算</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230415155136887.png" alt="image-20230415155136887"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://luke-blog.netlify.app/2023/04/11/%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/headIcon.jpg">
      <meta itemprop="name" content="Luke">
      <meta itemprop="description" content="我爱学习！~~~">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Luke-blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/04/11/%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" class="post-title-link" itemprop="url">零基础入门深度学习 - 卷积神经网络</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-04-11 10:47:20" itemprop="dateCreated datePublished" datetime="2023-04-11T10:47:20+08:00">2023-04-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-04-20 15:45:07" itemprop="dateModified" datetime="2023-04-20T15:45:07+08:00">2023-04-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">零基础入门深度学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="0x-1-它可以做什么？"><a href="#0x-1-它可以做什么？" class="headerlink" title="0x 1 它可以做什么？"></a>0x 1 它可以做什么？</h2><p>图像分类</p>
<h2 id="0x-2-博客学习"><a href="#0x-2-博客学习" class="headerlink" title="0x 2 博客学习"></a>0x 2 博客学习</h2><h3 id="Relu函数-（新的激活函数）"><a href="#Relu函数-（新的激活函数）" class="headerlink" title="Relu函数 （新的激活函数）"></a>Relu函数 （新的激活函数）</h3><p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230411141548885.png" alt="image-20230411141548885"></p>
<p>它的图像张这样：</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230411141603148.png" alt="image-20230411141603148"></p>
<blockquote>
<p>  为啥要用Relu?</p>
</blockquote>
<ul>
<li><p>速度快</p>
</li>
<li><p><mark>减轻梯度消失问题(啥意思？)</mark></p>
</li>
<li><p>稀疏性</p>
</li>
</ul>
<h3 id="啥是卷积神经网络"><a href="#啥是卷积神经网络" class="headerlink" title="啥是卷积神经网络"></a>啥是卷积神经网络</h3><blockquote>
<p>  感性认识</p>
</blockquote>
<p>一张彩色图片 &#x3D; 3-D tensor</p>
<p>哪三个d呢？</p>
<ul>
<li>图片宽 W</li>
<li>图片高 H</li>
<li>图片的 channels</li>
</ul>
<p>图像分类其实不需要使用全连接，原因是：我只需要图像当中个别的几个特征（<mark>非常有辨识度的</mark>），就能够辨别出这是个什么玩意，就是下图所示的这种感觉~~</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230411110443341.png" alt="image-20230411110443341"></p>
<p>使用全连接就有些像扔给神经元的全是完整的图片。</p>
<p>怎么做呢？</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230411111559626.png" alt="image-20230411111559626"></p>
<p>同样的特征可能出现图片当中的不同地方，像上面的这种全地图扫描的方式，确实不会漏掉特征，但是还是整个系统还是有些庞大~</p>
<p>Solution: 共享参数（weight一样），但是field不一样</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230411134729710.png" alt="image-20230411134729710"></p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230411143558503.png" alt="image-20230411143558503"></p>
<p>Q：从input image 到 feature maps    1-&gt;3的这个数量变化是怎么来的？</p>
<p>A: </p>
<ul>
<li>每一个filter进行一次卷积后都会得到一个Feature map,所以从input image 到 feature maps应该是有三个filter。</li>
</ul>
<p>简单说：</p>
<ul>
<li>Convolution Layer使用Filter得到Feature Maps    (寻找特征的过程)</li>
<li>Pooling Layer是对Feature Map进行采样的过程 (寻找最明显特征的过程)</li>
</ul>
<h3 id="Filter是怎么工作的？"><a href="#Filter是怎么工作的？" class="headerlink" title="Filter是怎么工作的？"></a>Filter是怎么工作的？</h3><p>stride &#x3D; 1（步幅为1）</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/20190715200135421.gif" alt="20190715200135421"></p>
<p>stride &#x3D; 2时：</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230411150607336.png" alt="image-20230411150607336"></p>
<p>所以说，最终的Feature Map大小有个公式</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230411150645429.png" alt="image-20230411150645429"></p>
<ul>
<li><em>W</em>2是卷积后Feature Map的宽度</li>
<li><em>W</em>1是卷积前图像的宽度</li>
<li><em>F</em>是filter的宽度</li>
<li><em>P</em>是Zero Padding数量，Zero Padding是指在原始图像周围补几圈0，如果的值是1，那么就补1圈0；</li>
<li><em>S</em>是步幅；</li>
<li><em>H</em>2是卷积后Feature Map的高度；</li>
<li>H1是卷积前图像的宽度</li>
</ul>
<h3 id="深度为1的卷积层计算方法："><a href="#深度为1的卷积层计算方法：" class="headerlink" title="深度为1的卷积层计算方法："></a>深度为1的卷积层计算方法：</h3><p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230411152036255.png" alt="image-20230411152036255"></p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/20190715200135421.gif" alt="20190715200135421"></p>
<h3 id="深度大于1的卷积层计算方法："><a href="#深度大于1的卷积层计算方法：" class="headerlink" title="深度大于1的卷积层计算方法："></a>深度大于1的卷积层计算方法：</h3><p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230412145431694.png" alt="image-20230412145431694"></p>
<p>例如：</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/20190715200149945.gif" alt="20190715200149945"></p>
<p>上面的图意思就是：有三个Channel，两个filter的计算方法，立体一点的话，就是这样子：</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230412145713517.png" alt="image-20230412145713517"></p>
<p>but，上面的公式是不是有点复杂，能不能精简一下？</p>
<p>能，但是只能在stride&#x3D;1的情况下进行精简——卷积公式</p>
<blockquote>
<p>  卷积公式</p>
</blockquote>
<p>我们在概率论当中学习过卷积公式，但是数学的卷积公式和卷积神经网络当中的卷积是有区别的：</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/%E6%97%A0%E6%A0%87%E9%A2%98.png" alt="无标题"></p>
<h3 id="Pooling-层输出值的计算"><a href="#Pooling-层输出值的计算" class="headerlink" title="Pooling 层输出值的计算"></a>Pooling 层输出值的计算</h3><p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230411154043592.png" alt="image-20230411154043592"></p>
<p>取出Feature Map当中最重要的样本，从而减少参数数量。</p>
<p>这里用的是Max Pooling。</p>
<p>其他的还有Mean Pooling….</p>
<h3 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h3><p>没啥说的</p>
<h3 id="卷积神经网络的训练"><a href="#卷积神经网络的训练" class="headerlink" title="卷积神经网络的训练"></a>卷积神经网络的训练</h3><p>和全连接神经网络相比，卷积神经网络的训练要复杂一些。但训练的原理是一样的：</p>
<p>利用链式求导计算损失函数<mark>对每个权重的偏导数（梯度）</mark>，然后根据梯度下降公式更新权重。训练算法依然是反向传播算法。</p>
<blockquote>
<p>  卷积层的<mark>误差项</mark>传递   (注意是误差项(E<sub>d</sub>对net求导)，不是误差(E<sub>d</sub>))</p>
</blockquote>
<p>步长为1时的误差</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E6%A1%A3(10)_1_1681296821894.png" alt="未命名文档(10)_1_1681296821894"></p>
<p>步长&gt;1时的误差(从步长为1的里面挑一挑就是了)：</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230412185529024.png" alt="image-20230412185529024"></p>
<blockquote>
<p>  卷积层 filter权重梯度的计算（有疑问）</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E6%A1%A3(10)_2_1681299279585.png" alt="未命名文档(10)_2_1681299279585"></p>
<p>理解：image经过多个filter会产生多个channel，如果做反向传播的话，生成的三个channel对原来的image的误差是有”叠加“效果的。</p>
<blockquote>
<p>  Pooling层的训练</p>
</blockquote>
<p>无论max pooling还是mean pooling，都没有需要学习的参数。因此，在卷积神经网络的训练中，Pooling层需要做的仅仅是将误差项传递到上一层，而没有梯度的计算。</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E6%A1%A3(10)_5_1681301675670.png" alt="未命名文档(10)_5_1681301675670"></p>
<h2 id="0x-3-python小知识"><a href="#0x-3-python小知识" class="headerlink" title="0x 3 python小知识"></a>0x 3 python小知识</h2><h3 id="random函数的用法"><a href="#random函数的用法" class="headerlink" title="random函数的用法"></a>random函数的用法</h3><p>code：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">weights = np.random.uniform(-<span class="number">1e-4</span>,<span class="number">1e-4</span>,(<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line">bias = <span class="number">0</span></span><br><span class="line">weight_grad = np.zeros(weights.shape)</span><br><span class="line"><span class="built_in">print</span>(weight_grad)</span><br></pre></td></tr></table></figure>

<p>output:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[[[0. 0. 0.]</span><br><span class="line">  [0. 0. 0.]</span><br><span class="line">  [0. 0. 0.]]</span><br><span class="line"></span><br><span class="line"> [[0. 0. 0.]</span><br><span class="line">  [0. 0. 0.]</span><br><span class="line">  [0. 0. 0.]]]</span><br></pre></td></tr></table></figure>





<h3 id="魔术方法-repr"><a href="#魔术方法-repr" class="headerlink" title="魔术方法 _repr_"></a>魔术方法 _<em>repr</em>_</h3><p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230413081441432.png" alt="image-20230413081441432"></p>
<p>就是说，实例化一个类的时候，会有一个回显</p>
<h3 id="np-nditer-函数"><a href="#np-nditer-函数" class="headerlink" title="np.nditer()函数"></a>np.nditer()函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.arange(<span class="number">6</span>).reshape(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"><span class="comment"># np.arange(6) 得到：[0 1 2 3 4 5]</span></span><br><span class="line"><span class="comment"># 再reshape一下，得到：[[0 1 2] [3 4 5]]</span></span><br><span class="line"><span class="keyword">with</span> np.nditer(a,op_flags = [<span class="string">&#x27;readwrite&#x27;</span>]) <span class="keyword">as</span> it: <span class="comment">#np.nditer(arrar,op_flags)会生成一个迭代器，我们叫他it</span></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> it:    <span class="comment">#使用nditer迭代器进行循环，速度要比for-loop快很多倍</span></span><br><span class="line">        x[...] = <span class="number">2</span>*x <span class="comment">#x[...]是一种“扩展切片”（Ellipsis slicing）的写法，它表示对数组中所有元素进行操作。</span></span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="在做padding的时候的代码解析："><a href="#在做padding的时候的代码解析：" class="headerlink" title="在做padding的时候的代码解析："></a>在做padding的时候的代码解析：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> input_array.ndim == <span class="number">3</span>:   <span class="comment">#ndim 是数组的维度</span></span><br><span class="line">    input_width = input_array.shape[<span class="number">2</span>]</span><br><span class="line">    input_height = input_array.shape[<span class="number">1</span>]</span><br><span class="line">    input_depth = input_array.shape[<span class="number">0</span>]</span><br><span class="line">    padded_array = np.zeros((</span><br><span class="line">        input_depth,</span><br><span class="line">        input_height + <span class="number">2</span>*zp,</span><br><span class="line">        input_width + <span class="number">2</span>*zp</span><br><span class="line">    ))</span><br><span class="line">    padded_array[:,</span><br><span class="line">        zp:zp + input_height,</span><br><span class="line">        zp:zp +input_width</span><br><span class="line">    ] = input_array</span><br><span class="line">    <span class="keyword">return</span> padded_array</span><br><span class="line"><span class="keyword">elif</span> input_array.ndim==<span class="number">2</span>:</span><br><span class="line">    input_width = input_array.shape[<span class="number">1</span>]</span><br><span class="line">    input_height = input_array.shpe[<span class="number">0</span>]</span><br><span class="line">    padded_array = np.zeros((</span><br><span class="line">        input_height + <span class="number">2</span>*zp,</span><br><span class="line">        input_width + <span class="number">2</span>*zp</span><br><span class="line">    ))</span><br><span class="line">    padded_array[</span><br><span class="line">        zp:zp+input_height+<span class="number">2</span>*zp,</span><br><span class="line">        zp:zp + input_width</span><br><span class="line">    ] = input_array</span><br><span class="line">    <span class="keyword">return</span> padded_array</span><br></pre></td></tr></table></figure>

<p>核心考察点：numpy数组当中，冒号的使用</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230413093313261.png" alt="image-20230413093313261"></p>
<p>简单说流程： 找到填充的位置，进行填充</p>
<h3 id="使用numpy数组的时候，它完全就是一个向量-x2F-矩阵"><a href="#使用numpy数组的时候，它完全就是一个向量-x2F-矩阵" class="headerlink" title="使用numpy数组的时候，它完全就是一个向量&#x2F;矩阵"></a>使用numpy数组的时候，它完全就是一个向量&#x2F;矩阵</h3><p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230413111439816.png" alt="image-20230413111439816"></p>
<p>可以去做向量减法、矩阵乘法等等操作。。。</p>
<h3 id="numpy数组的shape属性"><a href="#numpy数组的shape属性" class="headerlink" title="numpy数组的shape属性"></a>numpy数组的shape属性</h3><p>二维：</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230413145942055.png" alt="image-20230413145942055"></p>
<p>shape[0] ：有几行</p>
<p>shape[1]：有几列</p>
<p>三维：</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230413150004377.png" alt="image-20230413150004377"></p>
<p>shape[0] ：有几层 （channel数）</p>
<p>shape[1] ： 有几行</p>
<p>shape[2] : 有几列 </p>
<h2 id="0x-4-代码实现盘逻辑-amp-debug"><a href="#0x-4-代码实现盘逻辑-amp-debug" class="headerlink" title="0x 4 代码实现盘逻辑 &amp; debug"></a>0x 4 代码实现盘逻辑 &amp; debug</h2><p>以下为矢量图，可以下载下来放大看</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AE%9E%E7%8E%B0.svg" alt="卷积神经网络的实现"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://luke-blog.netlify.app/2023/04/09/%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/headIcon.jpg">
      <meta itemprop="name" content="Luke">
      <meta itemprop="description" content="我爱学习！~~~">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Luke-blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/04/09/%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95/" class="post-title-link" itemprop="url">零基础入门深度学习 - 神经网络和反向传播算法</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-04-09 20:25:02" itemprop="dateCreated datePublished" datetime="2023-04-09T20:25:02+08:00">2023-04-09</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-04-22 20:48:23" itemprop="dateModified" datetime="2023-04-22T20:48:23+08:00">2023-04-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">零基础入门深度学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1MP4y1E7vu?t=805.2&p=72">最简单的理解方法</a></p>
<h2 id="0x0-前置知识学的有啥用？"><a href="#0x0-前置知识学的有啥用？" class="headerlink" title="0x0 前置知识学的有啥用？"></a>0x0 前置知识学的有啥用？</h2><p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230410195117236.png" alt="image-20230410195117236"></p>
<h2 id="0x1-这节课学的东西，它能干啥呢❓"><a href="#0x1-这节课学的东西，它能干啥呢❓" class="headerlink" title="0x1 这节课学的东西，它能干啥呢❓"></a>0x1 这节课学的东西，它能干啥呢❓</h2><p>手写数字识别？？！！</p>
<h2 id="0x2-怎么搞？？"><a href="#0x2-怎么搞？？" class="headerlink" title="0x2 怎么搞？？"></a>0x2 怎么搞？？</h2><p>前面学习的都是训练<mark>单个神经元</mark>，回顾一下，前面干了些什么：</p>
<ul>
<li>感知器模拟and运算</li>
<li>预测工资</li>
</ul>
<p>现在学习的，就是将这些单个神经元（感知器）链接在一起，形成神经网络！</p>
<p>糟了，感觉太神奇了！</p>
<h2 id="0x3-理论学习🖊"><a href="#0x3-理论学习🖊" class="headerlink" title="0x3 理论学习🖊"></a>0x3 理论学习🖊</h2><h3 id="神经元-V-S-感知器"><a href="#神经元-V-S-感知器" class="headerlink" title="神经元 V.S. 感知器"></a>神经元 V.S. 感知器</h3><p>鲁迅曾说过：神经元与感知器虽说一样，但有点不一样🙈</p>
<ul>
<li>不一样点：神经元激活函数往往选择为sigmoid函数或tanh函数，而我们说感知器的时候，它的激活函数是阶跃函数</li>
</ul>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230409204803400.png" alt="image-20230409204803400"></p>
<h3 id="啥是神经网络？"><a href="#啥是神经网络？" class="headerlink" title="啥是神经网络？"></a>啥是神经网络？</h3><p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230409204400130.png" alt="image-20230409204400130"></p>
<p>上面这种是<mark>全连接神经网络的结构</mark>。事实上还存在很多其它结构的神经网络，比如卷积神经网络(CNN)、循环神经网络(RNN)，他们都具有不同的连接规则。</p>
<h3 id="神经网络怎么干活？"><a href="#神经网络怎么干活？" class="headerlink" title="神经网络怎么干活？"></a>神经网络怎么干活？</h3><p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230409204400130.png" alt="image-20230409204400130"></p>
<ul>
<li><p>如何计算a4的值？</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230409205221141.png" alt="image-20230409205221141"></p>
<p>上面的式子咋来的？</p>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230409205401484.png" alt="image-20230409205401484"></p>
<ul>
<li>如何计算y1?</li>
</ul>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230409205456810.png" alt="image-20230409205456810"></p>
<p>上面的式子咋来的？</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230409205530209.png" alt="image-20230409205530209"></p>
<ul>
<li>来波小小的summary</li>
</ul>
<p>简单讲： 输入是<img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230409205650061.png" alt="image-20230409205650061"> 输出是<img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230409205710388.png" alt="image-20230409205710388">，怎么做到的——神经网络~</p>
<p>如何用数学来理解？</p>
<p>hidden layer实际上是一个matrix， 向量进去之后，空间发生了扭曲变换，上面的这个变换就像是“二向箔”，形成了新的vector</p>
<h3 id="神经网络的训练"><a href="#神经网络的训练" class="headerlink" title="神经网络的训练"></a>神经网络的训练</h3><p>神经网络是一个<strong>模型</strong></p>
<p>权值是模型的<strong>参数</strong></p>
<p>一个神经网络的<strong>连接方式、网络的层数、每层的节点数</strong>这些参数，则不是学习出来的，而是人为事先设置的。对于这些人为设置的参数，我们称之为**超参数(Hyper-Parameters)**。</p>
<h3 id="反向传播算法-通过结果看原因"><a href="#反向传播算法-通过结果看原因" class="headerlink" title="反向传播算法(通过结果看原因)"></a>反向传播算法(通过结果看原因)</h3><p>⭐⭐⭐⭐<strong>一句话说</strong>：从后向前，利用误差项的计算和权重更新方法，计算出w<sub>ji</sub>更新所需要用到的δ</p>
<blockquote>
<p>   啥意思？为啥叫反向传播算法？</p>
</blockquote>
<p>举个有监督模型的例子：<strong>高中语文阅读理解题（特点：主观性强）</strong></p>
<p>简单说：</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230410080326438.png" alt="image-20230410080326438"></p>
<ol>
<li><p>有监督&#x3D;&gt;有答案的练习册，我做完题之后可以对答案</p>
</li>
<li><p>对答案时，我发现我写的不太好</p>
<p>怎么不好呢？&#x3D;&gt; 输出的Y 和我 答案上的 T相差比较大 (通过误差项估计可以看出来)</p>
</li>
<li><p>那<strong>写的不好</strong>（<strong>output layer</strong>），我就要找找原因了，也许是<strong>学习方法的问题</strong> </p>
<ol>
<li>我先根据误差，对自己写的答案进行了一点修改 （到了<strong>hidden layer</strong>）</li>
<li>修改了一点后，我悟了，原来是最开始的时候，审题审的不好，那么再根据误差修改我的审题思路(到了 <strong>input layer</strong>)</li>
</ol>
</li>
</ol>
<blockquote>
<p>   Q&amp;A:</p>
</blockquote>
<p>Q：我改的是什么？</p>
<p>A：改的其实是每一个神经元的w,也就是权重</p>
<p>Q：改完之后，能干啥啊？</p>
<p>A：改完之后，输出就更接近真实的答案了。给分也就会更高。</p>
<blockquote>
<p>  用数学理解 反向传播算法（🐕🐕🐕）</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230410080326438.png" alt="image-20230410080326438"></p>
<p><strong>用矩阵来描述上面的这个神经网络：</strong></p>
<p>令：</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230410200957859.png" alt="image-20230410200957859"></p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230410201019107.png" alt="image-20230410201019107"></p>
<p>从而：</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230410201102748.png" alt="image-20230410201102748"></p>
<p>最终有：</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230410201124073.png" alt="image-20230410201124073"></p>
<p><strong>更新权值相关公式（这在5.2.1、5.2.2中有推导过程）：</strong></p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230410195407536.png" alt="image-20230410195407536"></p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230410195428081.png" alt="image-20230410195428081"></p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230410195503148.png" alt="image-20230410195503148"></p>
<p>能用这个式子的理由：梯度下降法</p>
<p><mark>这段话非常重要：</mark>显然，计算一个节点的误差项，需要先计算每个与其相连的下一层节点的误差项。这就要求误差项的计算顺序必须是从输出层开始，然后反向依次计算每个隐藏层的误差项，直到与输入层相连的那个隐藏层。这就是反向传播算法的名字的含义。当所有节点的误差项计算完毕后，我们就可以根据<strong>式5</strong>来更新所有的权重。</p>
<p>看看，式子5当中的</p>
<ul>
<li><p><em>η</em>是学习速率</p>
</li>
<li><p><em>δ</em> <sub><em>j</em></sub>是节点j 的误差项（<mark>注意:</mark>误差项和误差不是一个东西）</p>
</li>
<li><p>x<sub>ji</sub>是节点i传递给节点j的输入</p>
</li>
<li><p>我的目的：让输出T与Y的误差变小</p>
<ul>
<li><p>误差怎么估计？ &#x3D;&gt; <img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230410091217289.png" alt="image-20230410091217289"></p>
</li>
<li><p>梯度下降法：出误差E <sub>d</sub>对于每个权重w<sub>ji</sub>的偏导数（也就是梯度）<img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230410193604139.png" alt="image-20230410193604139" style="zoom: 67%;" />这就有回到了式(5)</p>
</li>
<li><p>计算出误差E <sub>d</sub>对于每个权重w<sub>ji</sub>的偏导数的目的：修改wji</p>
</li>
<li><p>修改w<sub>ji</sub>的目的：让误差变小</p>
</li>
</ul>
</li>
</ul>
<h2 id="0x4-python语法知识补充-🎈"><a href="#0x4-python语法知识补充-🎈" class="headerlink" title="0x4 python语法知识补充 🎈"></a>0x4 python语法知识补充 🎈</h2><h3 id="a-1-V-S-a-1-V-S-a-1"><a href="#a-1-V-S-a-1-V-S-a-1" class="headerlink" title="a[-1] V.S. a[:-1] V.S. a[::-1]"></a>a[-1] V.S. a[:-1] V.S. a[::-1]</h3><p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230410144632783.png" alt="image-20230410144632783"></p>
<h2 id="0x5-写写代码、搞懂整体逻辑"><a href="#0x5-写写代码、搞懂整体逻辑" class="headerlink" title="0x5 写写代码、搞懂整体逻辑"></a>0x5 写写代码、搞懂整体逻辑</h2><p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/%E7%9B%98%E4%B8%80%E7%9B%98%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95%E5%92%8C%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E7%9A%84%E9%80%BB%E8%BE%91%20%E6%A0%B8%E5%BF%83%EF%BC%9ANetwork%E7%B1%BB.svg" alt="盘一盘反向传播算法和代码实现的逻辑 核心：Network类"></p>
<h2 id="0x6-如何保证自己的神经网络没有BUG"><a href="#0x6-如何保证自己的神经网络没有BUG" class="headerlink" title="0x6 如何保证自己的神经网络没有BUG?"></a>0x6 如何保证自己的神经网络没有BUG?</h2><p>核心：</p>
<p>将神经网络代码算出来的梯度值和手算出来的梯度值进行比较，如果差别比较小，就说明代码是正确的。</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230411090826503.png" alt="image-20230411090826503"></p>
<h2 id="0x7-手写数字识别"><a href="#0x7-手写数字识别" class="headerlink" title="0x7 手写数字识别"></a>0x7 手写数字识别</h2><p><strong>准备数据集：MNIST数据集</strong></p>
<h3 id="超参数"><a href="#超参数" class="headerlink" title="超参数"></a>超参数</h3><p>超参数（hyperparameters）是指机器学习模型中需要手动设置的参数，这些参数不能通过训练数据自动学习得到。 通常，超参数需要在训练过程前手动调整，以优化模型的性能和准确性。</p>
<p>超参数通常包括<mark>模型的学习率、正则化参数、批量大小、层数、神经元数量等</mark>。这些参数的设置可以对模型的效果产生重要影响，因此超参数的选择是非常重要的。</p>
<p>为了找到最佳的超参数组合，可以使用交叉验证等技术来评估模型的性能，并尝试不同的超参数值来找到最佳的超参数组合。</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230411091321710.png" alt="image-20230411091321710"></p>
<h3 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h3><p>错误率&#x3D;错误预测样本数&#x2F;总样本数</p>
<h2 id="0x8-向量化编程"><a href="#0x8-向量化编程" class="headerlink" title="0x8 向量化编程"></a>0x8 向量化编程</h2><p>区别于面向对象、面向过程</p>
<p>why? &#x3D;&gt; GPU可以对向量运算进行优化</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230411092620519.png" alt="image-20230411092620519"></p>
<p>通过上面的这一个公式，来实现全连接层向前和向后计算</p>
<p>对比面向对象的写法：</p>
<p>面向对象是一步一步向前面的Layer迭代的，向量化是对整个网络直接操作的</p>
<h2 id="0x-9手推公式"><a href="#0x-9手推公式" class="headerlink" title="0x 9手推公式"></a>0x 9手推公式</h2><p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E6%A1%A3(10)_2_1681288291648.png" alt="未命名文档(10)_2_1681288291648"></p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E6%A1%A3(10)_3_1681288363607.png" alt="未命名文档(10)_3_1681288363607"></p>
<pre><code>

</code></pre>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://luke-blog.netlify.app/2023/04/09/%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/headIcon.jpg">
      <meta itemprop="name" content="Luke">
      <meta itemprop="description" content="我爱学习！~~~">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Luke-blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/04/09/%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95/" class="post-title-link" itemprop="url">零基础入门深度学习 - 梯度下降算法</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-04-09 15:29:31" itemprop="dateCreated datePublished" datetime="2023-04-09T15:29:31+08:00">2023-04-09</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-04-11 16:17:26" itemprop="dateModified" datetime="2023-04-11T16:17:26+08:00">2023-04-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">零基础入门深度学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="0x1-这是要干啥？？？🐕🐕🐕"><a href="#0x1-这是要干啥？？？🐕🐕🐕" class="headerlink" title="0x1 这是要干啥？？？🐕🐕🐕"></a>0x1 这是要干啥？？？🐕🐕🐕</h2><h3 id="目的：我想让误差函数的值变小，咋办？"><a href="#目的：我想让误差函数的值变小，咋办？" class="headerlink" title="目的：我想让误差函数的值变小，咋办？"></a>目的：我想让误差函数的值变小，咋办？</h3><p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230409154853341.png" alt="image-20230409154853341"></p>
<p>E是可导函数。</p>
<p>求导！找极小值！然后再看端点！</p>
<h2 id="0x2-画画重点"><a href="#0x2-画画重点" class="headerlink" title="0x2 画画重点"></a>0x2 画画重点</h2><h3 id="梯度下降算法"><a href="#梯度下降算法" class="headerlink" title="梯度下降算法"></a>梯度下降算法</h3><blockquote>
<p>  简单说：</p>
</blockquote>
<p>计算机不会求极值，but可导函数的极值有个特点：导数为0。</p>
<p>所以让计算机遍历函数，find极小值</p>
<blockquote>
<p>  涉及的几个关键词：</p>
</blockquote>
<p><mark>梯度下降算法的公式</mark>：</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230409155120140.png" alt="image-20230409155120140">(式1)</p>
<p>那么，我要想求E(w)的极值点，f(x)换成E(w)就行了</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230409155235721.png" alt="image-20230409155235721">(式2)</p>
<p>∇ E(w)的推导过程目前先不管，它是这样算的：</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230409155359570.png" alt="image-20230409155359570">(式3)</p>
<p>So,把式子3代入式子2就得到了：</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230409155519593.png" alt="image-20230409155519593">(式4)</p>
<p>Easy啊~ 一点强度没有！</p>
<h3 id="误差推导"><a href="#误差推导" class="headerlink" title="误差推导"></a>误差推导</h3><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/u011681952/article/details/93714665">(24条消息) 零基础入门深度学习(2) - 线性单元和梯度下降_Godswisdom的博客-CSDN博客</a></p>
<p><mark>疑惑点：对整个向量求导是什么意思？</mark></p>
<h3 id="随机梯度下降算法-SGD算法"><a href="#随机梯度下降算法-SGD算法" class="headerlink" title="随机梯度下降算法(SGD算法)"></a>随机梯度下降算法(SGD算法)</h3><blockquote>
<p>  why?????</p>
</blockquote>
<p>按照上面提到的<img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230409155359570.png" alt="image-20230409155359570">来寻找best参数，计算量非常大，更好的solution是SGD算法</p>
<blockquote>
<p>  怎么做的(没有详细介绍)</p>
</blockquote>
<p>在SGD算法中，<mark>每次更新的迭代，只计算一个样本</mark>。这样对于一个具有数百万样本的训练数据，完成一次遍历就会对更w 新数百万次，效率大大提升。由于样本的噪音和随机性，每次更新w 并不一定按照减少E 的方向。然而，虽然存在一定随机性，大量的更新总体上沿着减少E 的方向前进的，因此最后也能收敛到最小值附近。</p>
<p>对比BGD：</p>
<p><mark>理解：SGD工作的维度是1维，但是次数很多。BGD工作维度为1000000维（夸张的手法），但是次数很少</mark></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Luke"
      src="/images/headIcon.jpg">
  <p class="site-author-name" itemprop="name">Luke</p>
  <div class="site-description" itemprop="description">我爱学习！~~~</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">13</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Luke</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
