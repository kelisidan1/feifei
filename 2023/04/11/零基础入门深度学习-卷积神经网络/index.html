<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"luke-blog.netlify.app","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="0x 1 它可以做什么？图像分类 0x 2 博客学习Relu函数 （新的激活函数） 它的图像张这样：     为啥要用Relu?   速度快  减轻梯度消失问题(啥意思？)  稀疏性   啥是卷积神经网络   感性认识  一张彩色图片 &#x3D; 3-D tensor 哪三个d呢？  图片宽 W 图片高 H 图片的 channels  图像分类其实不需要使用全连接，原因是：我只需要图像当中个别的">
<meta property="og:type" content="article">
<meta property="og:title" content="零基础入门深度学习 - 卷积神经网络">
<meta property="og:url" content="https://luke-blog.netlify.app/2023/04/11/%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/index.html">
<meta property="og:site_name" content="Luke-blog">
<meta property="og:description" content="0x 1 它可以做什么？图像分类 0x 2 博客学习Relu函数 （新的激活函数） 它的图像张这样：     为啥要用Relu?   速度快  减轻梯度消失问题(啥意思？)  稀疏性   啥是卷积神经网络   感性认识  一张彩色图片 &#x3D; 3-D tensor 哪三个d呢？  图片宽 W 图片高 H 图片的 channels  图像分类其实不需要使用全连接，原因是：我只需要图像当中个别的">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230411141548885.png">
<meta property="og:image" content="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230411141603148.png">
<meta property="og:image" content="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230411110443341.png">
<meta property="og:image" content="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230411111559626.png">
<meta property="og:image" content="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230411134729710.png">
<meta property="og:image" content="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230411143558503.png">
<meta property="og:image" content="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/20190715200135421.gif">
<meta property="og:image" content="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230411150607336.png">
<meta property="og:image" content="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230411150645429.png">
<meta property="og:image" content="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230411152036255.png">
<meta property="og:image" content="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/20190715200135421.gif">
<meta property="og:image" content="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230412145431694.png">
<meta property="og:image" content="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/20190715200149945.gif">
<meta property="og:image" content="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230412145713517.png">
<meta property="og:image" content="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/%E6%97%A0%E6%A0%87%E9%A2%98.png">
<meta property="og:image" content="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230411154043592.png">
<meta property="og:image" content="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E6%A1%A3(10)_1_1681296821894.png">
<meta property="og:image" content="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230412185529024.png">
<meta property="og:image" content="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E6%A1%A3(10)_2_1681299279585.png">
<meta property="og:image" content="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E6%A1%A3(10)_5_1681301675670.png">
<meta property="og:image" content="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230413081441432.png">
<meta property="og:image" content="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230413093313261.png">
<meta property="og:image" content="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230413111439816.png">
<meta property="og:image" content="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230413145942055.png">
<meta property="og:image" content="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230413150004377.png">
<meta property="og:image" content="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AE%9E%E7%8E%B0.svg">
<meta property="article:published_time" content="2023-04-11T02:47:20.000Z">
<meta property="article:modified_time" content="2023-04-13T08:58:56.549Z">
<meta property="article:author" content="Luke">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230411141548885.png">

<link rel="canonical" href="https://luke-blog.netlify.app/2023/04/11/%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>零基础入门深度学习 - 卷积神经网络 | Luke-blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Luke-blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Legends never die！</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://luke-blog.netlify.app/2023/04/11/%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/headIcon.jpg">
      <meta itemprop="name" content="Luke">
      <meta itemprop="description" content="我爱学习！~~~">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Luke-blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          零基础入门深度学习 - 卷积神经网络
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-04-11 10:47:20" itemprop="dateCreated datePublished" datetime="2023-04-11T10:47:20+08:00">2023-04-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-04-13 16:58:56" itemprop="dateModified" datetime="2023-04-13T16:58:56+08:00">2023-04-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">零基础入门深度学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="0x-1-它可以做什么？"><a href="#0x-1-它可以做什么？" class="headerlink" title="0x 1 它可以做什么？"></a>0x 1 它可以做什么？</h2><p>图像分类</p>
<h2 id="0x-2-博客学习"><a href="#0x-2-博客学习" class="headerlink" title="0x 2 博客学习"></a>0x 2 博客学习</h2><h3 id="Relu函数-（新的激活函数）"><a href="#Relu函数-（新的激活函数）" class="headerlink" title="Relu函数 （新的激活函数）"></a>Relu函数 （新的激活函数）</h3><p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230411141548885.png" alt="image-20230411141548885"></p>
<p>它的图像张这样：</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230411141603148.png" alt="image-20230411141603148"></p>
<blockquote>
<p>  为啥要用Relu?</p>
</blockquote>
<ul>
<li><p>速度快</p>
</li>
<li><p><mark>减轻梯度消失问题(啥意思？)</mark></p>
</li>
<li><p>稀疏性</p>
</li>
</ul>
<h3 id="啥是卷积神经网络"><a href="#啥是卷积神经网络" class="headerlink" title="啥是卷积神经网络"></a>啥是卷积神经网络</h3><blockquote>
<p>  感性认识</p>
</blockquote>
<p>一张彩色图片 &#x3D; 3-D tensor</p>
<p>哪三个d呢？</p>
<ul>
<li>图片宽 W</li>
<li>图片高 H</li>
<li>图片的 channels</li>
</ul>
<p>图像分类其实不需要使用全连接，原因是：我只需要图像当中个别的几个特征（<mark>非常有辨识度的</mark>），就能够辨别出这是个什么玩意，就是下图所示的这种感觉~~</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230411110443341.png" alt="image-20230411110443341"></p>
<p>使用全连接就有些像扔给神经元的全是完整的图片。</p>
<p>怎么做呢？</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230411111559626.png" alt="image-20230411111559626"></p>
<p>同样的特征可能出现图片当中的不同地方，像上面的这种全地图扫描的方式，确实不会漏掉特征，但是还是整个系统还是有些庞大~</p>
<p>Solution: 共享参数（weight一样），但是field不一样</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230411134729710.png" alt="image-20230411134729710"></p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230411143558503.png" alt="image-20230411143558503"></p>
<p>Q：从input image 到 feature maps    1-&gt;3的这个数量变化是怎么来的？</p>
<p>A: </p>
<ul>
<li>每一个filter进行一次卷积后都会得到一个Feature map,所以从input image 到 feature maps应该是有三个filter。</li>
</ul>
<p>简单说：</p>
<ul>
<li>Convolution Layer使用Filter得到Feature Maps    (寻找特征的过程)</li>
<li>Pooling Layer是对Feature Map进行采样的过程 (寻找最明显特征的过程)</li>
</ul>
<h3 id="Filter是怎么工作的？"><a href="#Filter是怎么工作的？" class="headerlink" title="Filter是怎么工作的？"></a>Filter是怎么工作的？</h3><p>stride &#x3D; 1（步幅为1）</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/20190715200135421.gif" alt="20190715200135421"></p>
<p>stride &#x3D; 2时：</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230411150607336.png" alt="image-20230411150607336"></p>
<p>所以说，最终的Feature Map大小有个公式</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230411150645429.png" alt="image-20230411150645429"></p>
<ul>
<li><em>W</em>2是卷积后Feature Map的宽度</li>
<li><em>W</em>1是卷积前图像的宽度</li>
<li><em>F</em>是filter的宽度</li>
<li><em>P</em>是Zero Padding数量，Zero Padding是指在原始图像周围补几圈0，如果的值是1，那么就补1圈0；</li>
<li><em>S</em>是步幅；</li>
<li><em>H</em>2是卷积后Feature Map的高度；</li>
<li>H1是卷积前图像的宽度</li>
</ul>
<h3 id="深度为1的卷积层计算方法："><a href="#深度为1的卷积层计算方法：" class="headerlink" title="深度为1的卷积层计算方法："></a>深度为1的卷积层计算方法：</h3><p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230411152036255.png" alt="image-20230411152036255"></p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/20190715200135421.gif" alt="20190715200135421"></p>
<h3 id="深度大于1的卷积层计算方法："><a href="#深度大于1的卷积层计算方法：" class="headerlink" title="深度大于1的卷积层计算方法："></a>深度大于1的卷积层计算方法：</h3><p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230412145431694.png" alt="image-20230412145431694"></p>
<p>例如：</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/20190715200149945.gif" alt="20190715200149945"></p>
<p>上面的图意思就是：有三个Channel，两个filter的计算方法，立体一点的话，就是这样子：</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230412145713517.png" alt="image-20230412145713517"></p>
<p>but，上面的公式是不是有点复杂，能不能精简一下？</p>
<p>能，但是只能在stride&#x3D;1的情况下进行精简——卷积公式</p>
<blockquote>
<p>  卷积公式</p>
</blockquote>
<p>我们在概率论当中学习过卷积公式，但是数学的卷积公式和卷积神经网络当中的卷积是有区别的：</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/%E6%97%A0%E6%A0%87%E9%A2%98.png" alt="无标题"></p>
<h3 id="Pooling-层输出值的计算"><a href="#Pooling-层输出值的计算" class="headerlink" title="Pooling 层输出值的计算"></a>Pooling 层输出值的计算</h3><p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230411154043592.png" alt="image-20230411154043592"></p>
<p>取出Feature Map当中最重要的样本，从而减少参数数量。</p>
<p>这里用的是Max Pooling。</p>
<p>其他的还有Mean Pooling….</p>
<h3 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h3><p>没啥说的</p>
<h3 id="卷积神经网络的训练"><a href="#卷积神经网络的训练" class="headerlink" title="卷积神经网络的训练"></a>卷积神经网络的训练</h3><p>和全连接神经网络相比，卷积神经网络的训练要复杂一些。但训练的原理是一样的：</p>
<p>利用链式求导计算损失函数<mark>对每个权重的偏导数（梯度）</mark>，然后根据梯度下降公式更新权重。训练算法依然是反向传播算法。</p>
<blockquote>
<p>  卷积层的<mark>误差项</mark>传递   (注意是误差项(E<sub>d</sub>对net求导)，不是误差(E<sub>d</sub>))</p>
</blockquote>
<p>步长为1时的误差</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E6%A1%A3(10)_1_1681296821894.png" alt="未命名文档(10)_1_1681296821894"></p>
<p>步长&gt;1时的误差(从步长为1的里面挑一挑就是了)：</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230412185529024.png" alt="image-20230412185529024"></p>
<blockquote>
<p>  卷积层 filter权重梯度的计算（有疑问）</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E6%A1%A3(10)_2_1681299279585.png" alt="未命名文档(10)_2_1681299279585"></p>
<p>理解：image经过多个filter会产生多个channel，如果做反向传播的话，生成的三个channel对原来的image的误差是有”叠加“效果的。</p>
<blockquote>
<p>  Pooling层的训练</p>
</blockquote>
<p>无论max pooling还是mean pooling，都没有需要学习的参数。因此，在卷积神经网络的训练中，Pooling层需要做的仅仅是将误差项传递到上一层，而没有梯度的计算。</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E6%A1%A3(10)_5_1681301675670.png" alt="未命名文档(10)_5_1681301675670"></p>
<h2 id="0x-3-python小知识"><a href="#0x-3-python小知识" class="headerlink" title="0x 3 python小知识"></a>0x 3 python小知识</h2><h3 id="random函数的用法"><a href="#random函数的用法" class="headerlink" title="random函数的用法"></a>random函数的用法</h3><p>code：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">weights = np.random.uniform(-<span class="number">1e-4</span>,<span class="number">1e-4</span>,(<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line">bias = <span class="number">0</span></span><br><span class="line">weight_grad = np.zeros(weights.shape)</span><br><span class="line"><span class="built_in">print</span>(weight_grad)</span><br></pre></td></tr></table></figure>

<p>output:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[[[0. 0. 0.]</span><br><span class="line">  [0. 0. 0.]</span><br><span class="line">  [0. 0. 0.]]</span><br><span class="line"></span><br><span class="line"> [[0. 0. 0.]</span><br><span class="line">  [0. 0. 0.]</span><br><span class="line">  [0. 0. 0.]]]</span><br></pre></td></tr></table></figure>





<h3 id="魔术方法-repr"><a href="#魔术方法-repr" class="headerlink" title="魔术方法 _repr_"></a>魔术方法 _<em>repr</em>_</h3><p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230413081441432.png" alt="image-20230413081441432"></p>
<p>就是说，实例化一个类的时候，会有一个回显</p>
<h3 id="np-nditer-函数"><a href="#np-nditer-函数" class="headerlink" title="np.nditer()函数"></a>np.nditer()函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.arange(<span class="number">6</span>).reshape(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"><span class="comment"># np.arange(6) 得到：[0 1 2 3 4 5]</span></span><br><span class="line"><span class="comment"># 再reshape一下，得到：[[0 1 2] [3 4 5]]</span></span><br><span class="line"><span class="keyword">with</span> np.nditer(a,op_flags = [<span class="string">&#x27;readwrite&#x27;</span>]) <span class="keyword">as</span> it: <span class="comment">#np.nditer(arrar,op_flags)会生成一个迭代器，我们叫他it</span></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> it:    <span class="comment">#使用nditer迭代器进行循环，速度要比for-loop快很多倍</span></span><br><span class="line">        x[...] = <span class="number">2</span>*x <span class="comment">#x[...]是一种“扩展切片”（Ellipsis slicing）的写法，它表示对数组中所有元素进行操作。</span></span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="在做padding的时候的代码解析："><a href="#在做padding的时候的代码解析：" class="headerlink" title="在做padding的时候的代码解析："></a>在做padding的时候的代码解析：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> input_array.ndim == <span class="number">3</span>:   <span class="comment">#ndim 是数组的维度</span></span><br><span class="line">    input_width = input_array.shape[<span class="number">2</span>]</span><br><span class="line">    input_height = input_array.shape[<span class="number">1</span>]</span><br><span class="line">    input_depth = input_array.shape[<span class="number">0</span>]</span><br><span class="line">    padded_array = np.zeros((</span><br><span class="line">        input_depth,</span><br><span class="line">        input_height + <span class="number">2</span>*zp,</span><br><span class="line">        input_width + <span class="number">2</span>*zp</span><br><span class="line">    ))</span><br><span class="line">    padded_array[:,</span><br><span class="line">        zp:zp + input_height,</span><br><span class="line">        zp:zp +input_width</span><br><span class="line">    ] = input_array</span><br><span class="line">    <span class="keyword">return</span> padded_array</span><br><span class="line"><span class="keyword">elif</span> input_array.ndim==<span class="number">2</span>:</span><br><span class="line">    input_width = input_array.shape[<span class="number">1</span>]</span><br><span class="line">    input_height = input_array.shpe[<span class="number">0</span>]</span><br><span class="line">    padded_array = np.zeros((</span><br><span class="line">        input_height + <span class="number">2</span>*zp,</span><br><span class="line">        input_width + <span class="number">2</span>*zp</span><br><span class="line">    ))</span><br><span class="line">    padded_array[</span><br><span class="line">        zp:zp+input_height+<span class="number">2</span>*zp,</span><br><span class="line">        zp:zp + input_width</span><br><span class="line">    ] = input_array</span><br><span class="line">    <span class="keyword">return</span> padded_array</span><br></pre></td></tr></table></figure>

<p>核心考察点：numpy数组当中，冒号的使用</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230413093313261.png" alt="image-20230413093313261"></p>
<p>简单说流程： 找到填充的位置，进行填充</p>
<h3 id="使用numpy数组的时候，它完全就是一个向量-x2F-矩阵"><a href="#使用numpy数组的时候，它完全就是一个向量-x2F-矩阵" class="headerlink" title="使用numpy数组的时候，它完全就是一个向量&#x2F;矩阵"></a>使用numpy数组的时候，它完全就是一个向量&#x2F;矩阵</h3><p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230413111439816.png" alt="image-20230413111439816"></p>
<p>可以去做向量减法、矩阵乘法等等操作。。。</p>
<h3 id="numpy数组的shape属性"><a href="#numpy数组的shape属性" class="headerlink" title="numpy数组的shape属性"></a>numpy数组的shape属性</h3><p>二维：</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230413145942055.png" alt="image-20230413145942055"></p>
<p>shape[0] ：有几行</p>
<p>shape[1]：有几列</p>
<p>三维：</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/image-20230413150004377.png" alt="image-20230413150004377"></p>
<p>shape[0] ：有几层 （channel数）</p>
<p>shape[1] ： 有几行</p>
<p>shape[2] : 有几列 </p>
<h2 id="0x-4-代码实现盘逻辑-amp-debug"><a href="#0x-4-代码实现盘逻辑-amp-debug" class="headerlink" title="0x 4 代码实现盘逻辑 &amp; debug"></a>0x 4 代码实现盘逻辑 &amp; debug</h2><p>以下为矢量图，可以下载下来放大看</p>
<p><img src="https://raw.githubusercontent.com/kelisidan1/blogImg/main/img/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AE%9E%E7%8E%B0.svg" alt="卷积神经网络的实现"></p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2023/04/09/%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95/" rel="prev" title="零基础入门深度学习 - 神经网络和反向传播算法">
      <i class="fa fa-chevron-left"></i> 零基础入门深度学习 - 神经网络和反向传播算法
    </a></div>
      <div class="post-nav-item">
    <a href="/2023/04/13/%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="next" title="零基础入门深度学习-循环神经网络">
      零基础入门深度学习-循环神经网络 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#0x-1-%E5%AE%83%E5%8F%AF%E4%BB%A5%E5%81%9A%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="nav-number">1.</span> <span class="nav-text">0x 1 它可以做什么？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#0x-2-%E5%8D%9A%E5%AE%A2%E5%AD%A6%E4%B9%A0"><span class="nav-number">2.</span> <span class="nav-text">0x 2 博客学习</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Relu%E5%87%BD%E6%95%B0-%EF%BC%88%E6%96%B0%E7%9A%84%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%EF%BC%89"><span class="nav-number">2.1.</span> <span class="nav-text">Relu函数 （新的激活函数）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%95%A5%E6%98%AF%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-number">2.2.</span> <span class="nav-text">啥是卷积神经网络</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Filter%E6%98%AF%E6%80%8E%E4%B9%88%E5%B7%A5%E4%BD%9C%E7%9A%84%EF%BC%9F"><span class="nav-number">2.3.</span> <span class="nav-text">Filter是怎么工作的？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B7%B1%E5%BA%A6%E4%B8%BA1%E7%9A%84%E5%8D%B7%E7%A7%AF%E5%B1%82%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95%EF%BC%9A"><span class="nav-number">2.4.</span> <span class="nav-text">深度为1的卷积层计算方法：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B7%B1%E5%BA%A6%E5%A4%A7%E4%BA%8E1%E7%9A%84%E5%8D%B7%E7%A7%AF%E5%B1%82%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95%EF%BC%9A"><span class="nav-number">2.5.</span> <span class="nav-text">深度大于1的卷积层计算方法：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Pooling-%E5%B1%82%E8%BE%93%E5%87%BA%E5%80%BC%E7%9A%84%E8%AE%A1%E7%AE%97"><span class="nav-number">2.6.</span> <span class="nav-text">Pooling 层输出值的计算</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82"><span class="nav-number">2.7.</span> <span class="nav-text">全连接层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%AD%E7%BB%83"><span class="nav-number">2.8.</span> <span class="nav-text">卷积神经网络的训练</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#0x-3-python%E5%B0%8F%E7%9F%A5%E8%AF%86"><span class="nav-number">3.</span> <span class="nav-text">0x 3 python小知识</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#random%E5%87%BD%E6%95%B0%E7%9A%84%E7%94%A8%E6%B3%95"><span class="nav-number">3.1.</span> <span class="nav-text">random函数的用法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%AD%94%E6%9C%AF%E6%96%B9%E6%B3%95-repr"><span class="nav-number">3.2.</span> <span class="nav-text">魔术方法 _repr_</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#np-nditer-%E5%87%BD%E6%95%B0"><span class="nav-number">3.3.</span> <span class="nav-text">np.nditer()函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9C%A8%E5%81%9Apadding%E7%9A%84%E6%97%B6%E5%80%99%E7%9A%84%E4%BB%A3%E7%A0%81%E8%A7%A3%E6%9E%90%EF%BC%9A"><span class="nav-number">3.4.</span> <span class="nav-text">在做padding的时候的代码解析：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8numpy%E6%95%B0%E7%BB%84%E7%9A%84%E6%97%B6%E5%80%99%EF%BC%8C%E5%AE%83%E5%AE%8C%E5%85%A8%E5%B0%B1%E6%98%AF%E4%B8%80%E4%B8%AA%E5%90%91%E9%87%8F-x2F-%E7%9F%A9%E9%98%B5"><span class="nav-number">3.5.</span> <span class="nav-text">使用numpy数组的时候，它完全就是一个向量&#x2F;矩阵</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#numpy%E6%95%B0%E7%BB%84%E7%9A%84shape%E5%B1%9E%E6%80%A7"><span class="nav-number">3.6.</span> <span class="nav-text">numpy数组的shape属性</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#0x-4-%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E7%9B%98%E9%80%BB%E8%BE%91-amp-debug"><span class="nav-number">4.</span> <span class="nav-text">0x 4 代码实现盘逻辑 &amp; debug</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Luke"
      src="/images/headIcon.jpg">
  <p class="site-author-name" itemprop="name">Luke</p>
  <div class="site-description" itemprop="description">我爱学习！~~~</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">9</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">分类</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Luke</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
